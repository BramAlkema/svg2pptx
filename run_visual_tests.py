#!/usr/bin/env python3
"""
Visual Comparison Test Runner
============================

Standalone script to run visual comparison tests for SVG2PPTX.
Creates before/after screenshots and comparison pages.

Usage:
    python run_visual_tests.py

Output:
    tests/visual/results/visual_test_report.html - Main report with all comparisons
"""

import asyncio
import sys
import os
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent))

# Import our visual testing system
from tests.visual.test_visual_comparison import VisualComparisonTester, create_sample_test_cases

async def main():
    """Run visual comparison tests and generate report."""
    print("ğŸ¨ SVG2PPTX Visual Comparison Testing")
    print("=" * 50)

    # Create tester
    tester = VisualComparisonTester("tests/visual/results")
    test_cases = create_sample_test_cases()

    print(f"ğŸ“‹ Running {len(test_cases)} visual comparison tests...")
    print()

    # Run each test
    for i, test_case in enumerate(test_cases, 1):
        print(f"[{i}/{len(test_cases)}] Testing: {test_case.name}")
        print(f"   Description: {test_case.description}")

        result = await tester.run_visual_test(test_case)
        tester.test_results.append(result)

        if result['status'] == 'completed':
            print(f"   âœ… Completed successfully")
            print(f"   ğŸ“ Comparison: {result['files']['comparison_page']}")
        else:
            print(f"   âŒ Failed: {'; '.join(result.get('errors', ['Unknown error']))}")

        print()

    # Generate comprehensive report
    print("ğŸ“Š Generating comprehensive report...")
    report_path = await tester.generate_test_report()

    # Print summary
    total = len(tester.test_results)
    completed = len([r for r in tester.test_results if r['status'] == 'completed'])
    failed = len([r for r in tester.test_results if r['status'] == 'failed'])

    print()
    print("ğŸ“ˆ VISUAL TESTING SUMMARY")
    print("=" * 50)
    print(f"   ğŸ“Š Total tests: {total}")
    print(f"   âœ… Completed: {completed}")
    print(f"   âŒ Failed: {failed}")
    print(f"   ğŸ“ˆ Success rate: {completed/max(1,total)*100:.1f}%")
    print()
    print(f"ğŸ“„ Main Report: {report_path}")
    print(f"ğŸŒ View report: file://{report_path.absolute()}")
    print()

    # List individual comparison pages
    print("ğŸ” Individual Comparisons:")
    for result in tester.test_results:
        if result['status'] == 'completed' and 'comparison_page' in result['files']:
            test_name = result['test_case']['name']
            comparison_path = Path(result['files']['comparison_page'])
            print(f"   â€¢ {test_name}: file://{comparison_path.absolute()}")

    print()
    print("ğŸ¯ Use these comparison pages to:")
    print("   â€¢ Validate visual accuracy of conversions")
    print("   â€¢ Identify areas needing improvement")
    print("   â€¢ Document before/after changes")
    print("   â€¢ Create visual regression test baselines")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâŒ Testing interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ Testing failed: {e}")
        sys.exit(1)