#!/usr/bin/env python3
"""
End-to-End (E2E) Test for FontEmbeddingEngine

Tests complete font embedding workflows from text analysis to
embedded font creation, simulating real-world usage scenarios.
"""

import pytest
from pathlib import Path
import sys
import tempfile
import time
from unittest.mock import Mock, patch

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from core.services.font_embedding_engine import FontEmbeddingEngine
from core.services.font_service import FontService
from src.data.embedded_font import (
    EmbeddedFont
)


class TestFontEmbeddingEngineE2E:
    """
    End-to-end tests for FontEmbeddingEngine.

    Tests complete workflows from text analysis to font embedding.
    """

    @pytest.fixture
    def temp_workspace(self):
        """Create temporary workspace for E2E testing."""
        with tempfile.TemporaryDirectory() as temp_dir:
            workspace = Path(temp_dir)
            # Create subdirectories for organized testing
            (workspace / "fonts").mkdir()
            (workspace / "output").mkdir()
            (workspace / "cache").mkdir()
            yield workspace

    @pytest.fixture
    def sample_font_collection(self, temp_workspace):
        """
        Create sample font collection for E2E testing.

        Creates realistic font files with varying sizes and characteristics.
        """
        fonts = {}
        font_dir = temp_workspace / "fonts"

        # Create font files with different characteristics
        font_configs = [
            {
                'name': 'arial.ttf',
                'family': 'Arial',
                'data': b'Mock Arial font data with substantial content for realistic size testing' * 20,
                'embedding_allowed': True
            },
            {
                'name': 'times.ttf',
                'family': 'Times New Roman',
                'data': b'Mock Times New Roman font with different content characteristics' * 25,
                'embedding_allowed': True
            },
            {
                'name': 'restricted.ttf',
                'family': 'RestrictedFont',
                'data': b'Mock restricted font that cannot be embedded' * 15,
                'embedding_allowed': False
            },
            {
                'name': 'helvetica.otf',
                'family': 'Helvetica',
                'data': b'Mock Helvetica OpenType font with extended character set' * 30,
                'embedding_allowed': True
            }
        ]

        for config in font_configs:
            font_path = font_dir / config['name']
            font_path.write_bytes(config['data'])
            fonts[config['family']] = {
                'path': str(font_path),
                'size': len(config['data']),
                'embedding_allowed': config['embedding_allowed']
            }

        return fonts

    @pytest.fixture
    def realistic_text_samples(self):
        """
        Create realistic text samples for E2E testing.

        Represents actual document content that would be processed.
        """
        return {
            'simple_document': "Hello World!\nThis is a simple document with basic text.",

            'business_document': """
            QUARTERLY FINANCIAL REPORT
            Q3 2024 Performance Summary

            Revenue: $2,450,000 (+15.3% YoY)
            Expenses: $1,890,000 (+8.7% YoY)
            Net Income: $560,000 (+35.2% YoY)

            Key Highlights:
            • Strong growth in digital channels
            • Improved operational efficiency
            • Successful product launches

            For more information, contact investor.relations@company.com
            """,

            'multilingual_content': """
            Welcome / Bienvenue / Bienvenidos / 欢迎

            English: The quick brown fox jumps over the lazy dog.
            Français: Portez ce vieux whisky au juge blond qui fume.
            Español: El veloz murciélago hindú comía feliz cardillo y kiwi.
            中文: 快速的棕色狐狸跳过懒惰的狗。

            Special characters: àáâãäåæçèéêëìíîïñòóôõöøùúûüý
            Mathematical: ∑∏∫√∞≠≤≥±×÷
            Currency: $€£¥₹₽¢
            """,

            'technical_content': """
            # Advanced Font Processing Engine

            ## Implementation Details

            ```python
            def process_font_embedding(text, font_path):
                characters = extract_characters(text)
                subset = create_subset(font_path, characters)
                return optimize_subset(subset)
            ```

            ### Performance Metrics
            - Processing time: O(n log n)
            - Memory usage: Linear with character count
            - Compression ratio: 70-90% typical

            ## Error Codes
            - E001: Font file not found
            - E002: Embedding not permitted
            - E003: Subsetting failed
            """,

            'presentation_slides': [
                "Introduction to Font Embedding",
                "Benefits of Font Subsetting",
                "Implementation Architecture",
                "Performance Benchmarks",
                "Conclusion and Next Steps"
            ]
        }

    @pytest.fixture
    def e2e_system_components(self, sample_font_collection):
        """
        Setup complete system components for E2E testing.

        Creates integrated FontService and FontEmbeddingEngine.
        """
        # Extract font directory from collection
        font_paths = [Path(info['path']).parent for info in sample_font_collection.values()]
        unique_font_dirs = list(set(str(path) for path in font_paths))

        font_service = FontService(font_directories=unique_font_dirs)
        embedding_engine = FontEmbeddingEngine(font_service=font_service)

        return {
            'font_service': font_service,
            'embedding_engine': embedding_engine,
            'font_collection': sample_font_collection
        }

    def test_basic_e2e_workflow(self, e2e_system_components, realistic_text_samples, temp_workspace):
        """
        Test the basic end-to-end workflow.

        Executes complete workflow from text analysis to embedded font creation.
        """
        engine = e2e_system_components['embedding_engine']
        font_collection = e2e_system_components['font_collection']

        # Select font and text for testing
        arial_font = font_collection['Arial']
        test_text = realistic_text_samples['simple_document']

        # Mock the complete font processing pipeline
        with patch.object(engine._font_service, 'load_font_from_path') as mock_load:
            # Setup mock font
            mock_font = Mock()
            mock_font.__contains__ = Mock(return_value=True)
            mock_os2 = Mock()
            mock_os2.fsType = 0  # Installable
            mock_font.__getitem__ = Mock(return_value=mock_os2)
            mock_font.getGlyphSet.return_value = {f'glyph_{i}': None for i in range(1000)}
            mock_load.return_value = mock_font

            # Mock subsetting operation
            with patch.object(engine, '_perform_font_subsetting') as mock_subset:
                subset_data = b'optimized subset font data for Arial'
                mock_subset.return_value = subset_data

                with patch('os.path.getsize', return_value=arial_font['size']):

                    # Execute the complete workflow
                    start_time = time.time()
                    embedded_font = engine.create_embedding_for_text(
                        font_path=arial_font['path'],
                        text_content=test_text,
                        font_name='Arial',
                        optimization_level='basic'
                    )
                    processing_time = time.time() - start_time

        # Verify successful completion
        assert embedded_font is not None
        assert isinstance(embedded_font, EmbeddedFont)
        assert embedded_font.font_name == 'Arial'
        assert embedded_font.font_data == subset_data
        assert embedded_font.original_size == arial_font['size']
        assert embedded_font.embedding_allowed is True

        # Verify performance characteristics
        assert processing_time < 5.0  # Should complete quickly

        # Verify statistics were updated
        stats = engine.get_embedding_statistics()
        assert stats.total_fonts_processed >= 1
        assert stats.total_fonts_embedded >= 1

    def test_batch_processing_e2e(self, e2e_system_components, realistic_text_samples, temp_workspace):
        """
        Test end-to-end batch processing workflow.

        Processes multiple text-font combinations in a single operation.
        """
        engine = e2e_system_components['embedding_engine']
        font_collection = e2e_system_components['font_collection']

        # Create batch processing request
        batch_mappings = [
            {
                'text': realistic_text_samples['simple_document'],
                'font_path': font_collection['Arial']['path'],
                'font_name': 'Arial'
            },
            {
                'text': realistic_text_samples['business_document'],
                'font_path': font_collection['Times New Roman']['path'],
                'font_name': 'Times New Roman'
            },
            {
                'text': realistic_text_samples['technical_content'],
                'font_path': font_collection['Helvetica']['path'],
                'font_name': 'Helvetica'
            }
        ]

        # Mock the batch processing pipeline
        with patch.object(engine, 'create_embedding_for_text') as mock_create:
            # Create mock embedded fonts
            mock_fonts = []
            for i, mapping in enumerate(batch_mappings):
                mock_font = Mock(spec=EmbeddedFont)
                mock_font.font_name = mapping['font_name']
                mock_font.character_count = len(set(mapping['text']))
                mock_fonts.append(mock_font)

            mock_create.side_effect = mock_fonts

            # Execute batch processing
            start_time = time.time()
            results = engine.batch_create_embeddings(
                text_font_mappings=batch_mappings,
                optimization_level='basic'
            )
            batch_time = time.time() - start_time

        # Verify batch results
        assert len(results) == 3
        assert all(result is not None for result in results)
        assert results[0].font_name == 'Arial'
        assert results[1].font_name == 'Times New Roman'
        assert results[2].font_name == 'Helvetica'

        # Verify batch processing efficiency
        assert batch_time < 10.0  # Reasonable time for batch operation
        assert mock_create.call_count == 3

    def test_multilingual_content_e2e(self, e2e_system_components, realistic_text_samples, temp_workspace):
        """
        Test end-to-end processing of multilingual content.

        Verifies handling of Unicode characters and diverse character sets.
        """
        engine = e2e_system_components['embedding_engine']
        font_collection = e2e_system_components['font_collection']

        multilingual_text = realistic_text_samples['multilingual_content']

        # Extract characters from multilingual content
        characters = engine.extract_characters_from_text(multilingual_text)

        # Verify comprehensive character extraction
        assert len(characters) > 50  # Rich character set
        assert '欢' in characters    # Chinese characters
        assert 'ñ' in characters     # Spanish characters with diacritics
        assert 'ç' in characters     # French characters with cedilla
        assert '∑' in characters     # Mathematical symbols
        assert '€' in characters     # Currency symbols

        # Mock font processing for multilingual content
        with patch.object(engine._font_service, 'load_font_from_path') as mock_load:
            mock_font = Mock()
            mock_font.__contains__ = Mock(return_value=True)
            mock_os2 = Mock()
            mock_os2.fsType = 0
            mock_font.__getitem__ = Mock(return_value=mock_os2)
            mock_load.return_value = mock_font

            with patch.object(engine, '_perform_font_subsetting') as mock_subset:
                mock_subset.return_value = b'multilingual subset data'

                with patch('os.path.getsize', return_value=50000):

                    # Process multilingual content
                    embedded_font = engine.create_embedding_for_text(
                        font_path=font_collection['Arial']['path'],
                        text_content=multilingual_text,
                        font_name='Arial-Multilingual'
                    )

        # Verify successful multilingual processing
        assert embedded_font is not None
        assert embedded_font.character_count > 50

    def test_error_scenarios_e2e(self, e2e_system_components, temp_workspace):
        """
        Test end-to-end error handling scenarios.

        Verifies graceful handling of various error conditions.
        """
        engine = e2e_system_components['embedding_engine']

        error_scenarios = [
            {
                'name': 'non_existent_font',
                'font_path': str(temp_workspace / "nonexistent.ttf"),
                'text': "Test text",
                'expected_result': None
            },
            {
                'name': 'empty_text',
                'font_path': str(temp_workspace / "fonts" / "arial.ttf"),
                'text': "",
                'expected_result': None
            },
            {
                'name': 'invalid_characters',
                'font_path': str(temp_workspace / "fonts" / "arial.ttf"),
                'text': None,  # Invalid input type
                'expected_result': None
            }
        ]

        for scenario in error_scenarios:
            try:
                result = engine.create_embedding_for_text(
                    font_path=scenario['font_path'],
                    text_content=scenario['text'],
                    font_name=f"Test-{scenario['name']}"
                )

                # Verify expected result
                if scenario['expected_result'] is None:
                    assert result is None

            except Exception as e:
                # Some scenarios may raise exceptions - that's acceptable
                pass

        # Verify error statistics were recorded (at least one error)
        stats = engine.get_embedding_statistics()
        assert stats.total_fonts_failed >= 1

    def test_performance_optimization_e2e(self, e2e_system_components, realistic_text_samples, temp_workspace):
        """
        Test end-to-end performance with different optimization levels.

        Compares processing efficiency across optimization settings.
        """
        engine = e2e_system_components['embedding_engine']
        font_collection = e2e_system_components['font_collection']

        optimization_levels = ['none', 'basic', 'aggressive']
        test_text = realistic_text_samples['business_document']
        font_path = font_collection['Arial']['path']

        performance_results = {}

        # Mock the font processing for performance testing
        with patch.object(engine._font_service, 'load_font_from_path') as mock_load:
            mock_font = Mock()
            mock_font.__contains__ = Mock(return_value=True)
            mock_os2 = Mock()
            mock_os2.fsType = 0
            mock_font.__getitem__ = Mock(return_value=mock_os2)
            mock_load.return_value = mock_font

            for level in optimization_levels:
                with patch.object(engine, '_perform_font_subsetting') as mock_subset:
                    # Simulate different subset sizes based on optimization
                    base_size = 1000
                    if level == 'aggressive':
                        subset_size = int(base_size * 0.3)  # 70% reduction
                    elif level == 'basic':
                        subset_size = int(base_size * 0.5)  # 50% reduction
                    else:  # none
                        subset_size = int(base_size * 0.8)  # 20% reduction

                    mock_subset.return_value = b'x' * subset_size

                    with patch('os.path.getsize', return_value=10000):

                        # Measure processing time
                        start_time = time.time()
                        embedded_font = engine.create_embedding_for_text(
                            font_path=font_path,
                            text_content=test_text,
                            font_name=f'Arial-{level}',
                            optimization_level=level
                        )
                        processing_time = time.time() - start_time

                        performance_results[level] = {
                            'processing_time': processing_time,
                            'embedded_size': embedded_font.embedded_size if embedded_font else 0,
                            'compression_ratio': embedded_font.compression_ratio if embedded_font else 0
                        }

        # Verify optimization effectiveness
        # Aggressive should produce smallest files
        if performance_results['aggressive']['embedded_size'] > 0:
            assert (performance_results['aggressive']['embedded_size'] <=
                   performance_results['basic']['embedded_size'])
            assert (performance_results['basic']['embedded_size'] <=
                   performance_results['none']['embedded_size'])

    def test_cache_efficiency_e2e(self, e2e_system_components, realistic_text_samples, temp_workspace):
        """
        Test end-to-end cache efficiency and performance improvement.

        Verifies that caching improves performance for repeated operations.
        """
        engine = e2e_system_components['embedding_engine']
        font_collection = e2e_system_components['font_collection']

        test_text = realistic_text_samples['simple_document']
        font_path = font_collection['Arial']['path']

        # Mock font processing for cache testing
        with patch.object(engine._font_service, 'load_font_from_path') as mock_load:
            mock_font = Mock()
            mock_font.__contains__ = Mock(return_value=True)
            mock_os2 = Mock()
            mock_os2.fsType = 0
            mock_font.__getitem__ = Mock(return_value=mock_os2)
            mock_load.return_value = mock_font

            with patch.object(engine, '_perform_font_subsetting') as mock_subset:
                mock_subset.return_value = b'cached subset data'

                with patch('os.path.getsize', return_value=5000):

                    # Clear cache and measure first operation
                    engine.clear_cache()
                    initial_stats = engine.get_cache_stats()
                    assert initial_stats['cached_subsets'] == 0

                    # First operation (cache miss)
                    start_time = time.time()
                    result1 = engine.create_embedding_for_text(
                        font_path=font_path,
                        text_content=test_text,
                        font_name='Arial'
                    )
                    first_time = time.time() - start_time

                    # Verify cache was populated
                    cache_stats = engine.get_cache_stats()
                    assert cache_stats['cached_subsets'] == 1

                    # Second operation (cache hit)
                    start_time = time.time()
                    result2 = engine.create_embedding_for_text(
                        font_path=font_path,
                        text_content=test_text,
                        font_name='Arial'
                    )
                    second_time = time.time() - start_time

        # Verify cache effectiveness
        assert result1 == result2  # Same result
        assert mock_subset.call_count == 1  # Subsetting only called once
        # Second operation should be faster or at least not significantly slower
        assert second_time <= first_time * 2

    @pytest.mark.parametrize("content_type,optimization_level,expected_success", [
        ("simple_document", "basic", True),
        ("business_document", "aggressive", True),
        ("multilingual_content", "none", True),
        ("technical_content", "basic", True),
        ("presentation_slides", "aggressive", True),
    ])
    def test_e2e_content_scenarios(self, e2e_system_components, realistic_text_samples,
                                  content_type, optimization_level, expected_success, temp_workspace):
        """
        Test various end-to-end scenarios with different content types and settings.

        Parametrized testing of realistic content scenarios.
        """
        engine = e2e_system_components['embedding_engine']
        font_collection = e2e_system_components['font_collection']

        # Get test content
        if content_type in realistic_text_samples:
            test_content = realistic_text_samples[content_type]
        else:
            pytest.skip(f"Content type {content_type} not available")

        # Mock font processing
        with patch.object(engine._font_service, 'load_font_from_path') as mock_load:
            mock_font = Mock()
            mock_font.__contains__ = Mock(return_value=True)
            mock_os2 = Mock()
            mock_os2.fsType = 0
            mock_font.__getitem__ = Mock(return_value=mock_os2)
            mock_load.return_value = mock_font

            with patch.object(engine, '_perform_font_subsetting') as mock_subset:
                mock_subset.return_value = b'parametrized test subset data'

                with patch('os.path.getsize', return_value=8000):

                    # Execute the scenario
                    result = engine.create_embedding_for_text(
                        font_path=font_collection['Arial']['path'],
                        text_content=test_content,
                        font_name=f'Arial-{content_type}',
                        optimization_level=optimization_level
                    )

        # Verify expected outcome
        if expected_success:
            assert result is not None
            assert isinstance(result, EmbeddedFont)
            assert result.font_name == f'Arial-{content_type}'
        else:
            assert result is None


class TestFontEmbeddingEngineRealWorldWorkflows:
    """
    Tests for typical real-world font embedding workflows.

    Simulates actual usage patterns and requirements.
    """

    def test_document_preparation_workflow(self):
        """
        Test workflow for preparing document fonts for embedding.

        Simulates preparing a document with multiple fonts for distribution.
        """
        engine = FontEmbeddingEngine()

        # Simulate document with multiple font requirements
        document_sections = {
            'heading': {'text': 'IMPORTANT ANNOUNCEMENT', 'font': 'Arial-Bold'},
            'body': {'text': 'This document contains important information...', 'font': 'Arial'},
            'footer': {'text': 'Page 1 of 5', 'font': 'Arial-Italic'},
            'signature': {'text': 'John Doe, CEO', 'font': 'Times-Roman'}
        }

        # Mock the workflow
        embedded_fonts = []
        for section_name, section_info in document_sections.items():
            with patch.object(engine, 'create_embedding_for_text') as mock_create:
                mock_font = Mock(spec=EmbeddedFont)
                mock_font.font_name = section_info['font']
                mock_font.character_count = len(set(section_info['text']))
                mock_create.return_value = mock_font

                embedded_font = engine.create_embedding_for_text(
                    font_path=f"/fonts/{section_info['font'].lower()}.ttf",
                    text_content=section_info['text'],
                    font_name=section_info['font']
                )

                if embedded_font:
                    embedded_fonts.append(embedded_font)

        # Verify document preparation
        assert len(embedded_fonts) == len(document_sections)

    def test_presentation_optimization_workflow(self):
        """
        Test workflow for optimizing presentation fonts.

        Simulates optimizing fonts for a slide presentation.
        """
        engine = FontEmbeddingEngine()

        # Simulate presentation slides
        slide_contents = [
            "Welcome to Our Company",
            "Our Mission: Excellence in Service",
            "2024 Performance Highlights",
            "Future Growth Strategy",
            "Thank You for Your Attention"
        ]

        # Batch optimize fonts for presentation
        mappings = [
            {
                'text': content,
                'font_path': '/fonts/presentation.ttf',
                'font_name': f'Presentation-Slide-{i+1}'
            }
            for i, content in enumerate(slide_contents)
        ]

        with patch.object(engine, 'batch_create_embeddings') as mock_batch:
            # Simulate successful batch processing
            mock_results = [Mock(spec=EmbeddedFont) for _ in mappings]
            mock_batch.return_value = mock_results

            results = engine.batch_create_embeddings(
                text_font_mappings=mappings,
                optimization_level='aggressive'  # Optimize for file size
            )

        # Verify presentation optimization
        assert len(results) == len(slide_contents)
        assert all(result is not None for result in results)


if __name__ == "__main__":
    # Allow running tests directly
    pytest.main([__file__])